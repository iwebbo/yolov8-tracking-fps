# README : yolov8-tracking-fps

###ENGLISH VERSION COMING SOON
##üìå Prerequisites

##üñ• Hardware:

A computer capable of running Python and deep learning models.
An Arduino connected via a serial port (e.g., Arduino Uno).
A USB cable to connect the computer and the Arduino.

##üõ† Software:

Python 3.8+
PyTorch
Ultralytics YOLOv8 (pip install ultralytics)
ONNX and ONNX Runtime (pip install onnx onnxruntime)
A custom dataset annotated in YOLO format (using tools like LabelImg or Roboflow).

##üîß Dataset Organization

Your dataset should follow this structure:
```
custom_dataset/
|-- train/images/  # Training images
|-- train/labels/  # Corresponding YOLO format labels (.txt)
|-- val/images/    # Validation images
|-- val/labels/    # Corresponding validation labels

Each .txt file should contain annotations in YOLO format:

<class_id> <x_center> <y_center> <width> <height>
```
üëâ Find datasets: Roboflow Universe


Ce document explique comment effectuer l'entra√Ænement d'un mod√®le YOLOv8 sur un dataset personnalis√© pour la d√©tection d'objets, ainsi que la conversion du mod√®le final au format ONNX pour une int√©gration dans un script.

## Pr√©requis
- **Python 3.8+**
- **PyTorch**
- **Ultralytics YOLOv8** (installer via pip : `pip install ultralytics`)
- **onnx** et **onnxruntime** (installer via pip : `pip install onnx onnxruntime`)
- Un dataset personnalis√© annot√© dans le format YOLO (√† l‚Äôaide d‚Äôoutils comme [LabelImg](https://github.com/heartexlabs/labelImg) ou [Roboflow](https://roboflow.com/)).

## √âtapes de Training avec un Dataset Personnalis√©

### 1. Organisation du Dataset
Le dataset doit √™tre structur√© comme suit :
```
custom_dataset/
|-- train/images/  # Images pour l'entra√Ænement
|-- train/labels/  # Labels correspondants au format YOLO (.txt)
|-- val/images/    # Images pour la validation
|-- val/labels/    # Labels correspondants pour la validation
```
Chaque fichier `.txt` doit avoir les annotations des objets au format YOLO :
```
<class_id> <x_center> <y_center> <width> <height>
```
- `class_id` : ID de la classe
- `x_center`, `y_center`, `width`, `height` : coordonn√©es normalis√©es (entre 0 et 1).

- Ou trouver des dataset custom ?
- https://universe.roboflow.com

### 2. Configuration d‚Äôun fichier YAML
Cr√©ez un fichier `custom_dataset.yaml` contenant :
```yaml
task: detect
train: path/to/custom_dataset/train
val: path/to/custom_dataset/val

names:
  0: Enemy
  1: Weapon
```
Remplacez les chemins et les noms des classes par ceux de votre dataset.

### 3. Lancement de l‚Äôentra√Ænement

Au sein de cette function, nous d√©finissons quelle mod√®le utiliser : 
Merci de regarder la documentation offici√®lle : https://github.com/ultralytics/ultralytics 

Fonctionnalit√©s
Chargement du Mod√®le : Choisissez entre un mod√®le neuf, pr√©-entra√Æn√© ou avec transfert d'apprentissage.
Entra√Ænement : Sp√©cifiez le nombre d'√©poques et la taille des lots pour l'entra√Ænement.
Validation : Option pour valider le mod√®le apr√®s l'entra√Ænement.
Exportation : Possibilit√© d'exporter le mod√®le entra√Æn√© dans diff√©rents formats.

load (str) : M√©thode de chargement du mod√®le.
'new' : Cr√©e un nouveau mod√®le √† partir du fichier YAML.
'pre' : Charge un mod√®le pr√©-entra√Æn√©.
'tran' : Charge un mod√®le √† partir du YAML et applique un transfert d'apprentissage.
traindata (str) : Chemin vers le fichier de configuration des donn√©es d'entra√Ænement (par d√©faut : "fortnite.yaml").
epochs (int) : Nombre d'√©poques pour l'entra√Ænement (par d√©faut : 50).
batch_size (int) : Taille des lots pour l'entra√Ænement (par d√©faut : 16).
export (bool) : Indique si le mod√®le doit √™tre export√© apr√®s l'entra√Ænement (par d√©faut : True).
val (bool) : Indique si une validation doit √™tre effectu√©e apr√®s l'entra√Ænement (par d√©faut : True).

Utilisez le package `ultralytics` pour entra√Æner YOLOv8 :
```python
def custom_train(load='pre', traindata="fortnite.yaml", epochs=50, batch_size=16, export=True, val=True):
    # Chargement du mod√®le
    if load == 'new':
        model = YOLO('yolov8n.yaml')  # Construire un nouveau mod√®le √† partir du YAML
    elif load == 'pre':
        model = YOLO('yolov8n.pt')  # Charger un mod√®le pr√©-entra√Æn√©
    elif load == 'tran':
        model = YOLO('yolov8n.yaml').load('yolov8n.pt')  # Construire √† partir du YAML et transf√©rer les poids
```

Le mod√®le entra√Æn√© sera sauvegard√© dans le dossier `runs/detect/custom_model/`.

## Conversion au Format ONNX

Apr√®s l‚Äôentra√Ænement, vous pouvez convertir le mod√®le YOLOv8 au format ONNX pour l‚Äôint√©grer dans votre script :

### 1. Conversion
Utilisez le code suivant pour exporter le mod√®le :
```python
# Exporter le mod√®le au format ONNX
model.export(format='onnx')
```
Le fichier ONNX sera g√©n√©r√© dans le dossier `runs/detect/export/`.

### 2. Validation du Mod√®le PT
## Installation

1.  Assurez-vous d'avoir Python install√©.
2.  Installez les librairies requises :
    ```bash
    pip install torch ultralytics opencv-python
    ```

## Utilisation

1.  Placez votre mod√®le YOLOv8 entra√Æn√© (`best_fort.pt`) et l'image √† tester (`capture.jpg`) dans le m√™me r√©pertoire que le script.
2.  Modifiez le script :
    *   Mettez √† jour `model_path` et `image_path` si n√©cessaire.
    *   **Surtout, remplacez `["0", "1"]` dans `class_names` par les noms r√©els de vos classes.**
3.  Ex√©cutez le script :
    ```bash
    python check_from_capture_pt_file_detect.py
    ```

## R√©sultat

Une fen√™tre affichera l'image avec les objets d√©tect√©s, leurs bo√Ætes englobantes, leurs noms de classes et leurs confiances.
![capture](https://github.com/user-attachments/assets/29fd22e4-8ae5-478f-8973-0abbbff56de0)
![Capture d'√©cran 2025-02-02 184733](https://github.com/user-attachments/assets/2d829261-e280-41ce-a99a-d0819b8650b9)
![Capture d'√©cran 2025-02-01 223906](https://github.com/user-attachments/assets/4b017dfa-542e-42fe-a1dd-b44fc40a6575)

## Notes

*   Assurez-vous que votre mod√®le YOLOv8 est compatible avec la version de `ultralytics` que vous utilisez.
*   Si vous rencontrez des erreurs, v√©rifiez les chemins des fichiers et les noms de classes.

## Int√©gration dans le Script de D√©tection

### 3. Validation du mod√®le ONNX
Utilisation
Placez votre mod√®le ONNX (best_fort.onnx) et l'image √† tester (capture.jpg) dans le m√™me r√©pertoire que le script.
Modifiez le script :
Mettez √† jour model_path et image_path si n√©cessaire.
Surtout, remplacez ["0", "1"] dans class_names par les noms r√©els de vos classes.
Ajustez input_size si n√©cessaire (doit correspondre √† la taille d'entr√©e du mod√®le).
Ex√©cutez le script :
Bash

python check_from_capture_onnx_file_detect.py
R√©sultat
Une fen√™tre affichera l'image avec les objets d√©tect√©s, leurs bo√Ætes englobantes, leurs noms de classes et leurs confiances.

Notes
Assurez-vous que votre mod√®le ONNX est compatible avec ONNX Runtime.
Si vous rencontrez des erreurs, v√©rifiez les chemins des fichiers, les noms de classes et la taille d'entr√©e du mod√®le.
Ce script suppose que la sortie du mod√®le ONNX est un tableau numpy contenant les d√©tections au format attendu (voir la fonction postprocess_detections). Ce format est typique des mod√®les YOLO, mais peut varier. Si votre mod√®le a une sortie diff√©rente, vous devrez adapter la fonction postprocess_detections.

**Changements importants et explications :**

*   **Gestion des erreurs d'image:** Ajout d'une gestion des erreurs dans `preprocess_image` pour lever une exception si l'image ne peut pas √™tre lue.
*   **Image originale pour le dessin:** La fonction `preprocess_image` retourne maintenant l'image originale *et* l'image pr√©trait√©e. L'image originale est utilis√©e pour dessiner les bo√Ætes, car elle conserve la r√©solution originale.
*   **Inf√©rence ONNX:** L'ex√©cution de l'inf√©rence ONNX se fait avec `session.run()`.  Il est *crucial* de r√©cup√©rer la sortie du mod√®le correctement. J'ai ajout√© `[0]` √† la fin pour extraire le r√©sultat du tableau retourn√© par `session.run()`.  **V√©rifiez le format de sortie de votre mod√®le ONNX**.  Ce code suppose qu'il retourne un seul tenseur contenant les d√©tections.  Si ce n'est pas le cas, vous devrez adapter cette ligne.
*   **Transposition des d√©tections:** La boucle dans `postprocess_detections` utilise `.T` (transposition) pour it√©rer sur les d√©tections de mani√®re plus intuitive.
*   **Conversion en entiers:** La conversion des coordonn√©es de bo√Ætes en entiers est faite dans `draw_boxes`, juste avant de dessiner, pour plus de s√©curit√©.
*   **Commentaires:** Ajout de commentaires plus d√©taill√©s pour expliquer chaque √©tape.

## 4 Run & Test
Utilisation
Placez votre mod√®le YOLOv8 entra√Æn√© (best_fort.pt) dans le m√™me r√©pertoire que le script.
Ex√©cutez le script :
Bash

python live_check_yolov8.py

## Param√®tres:
CONFIDENCE_THRESHOLD : Seuil de confiance pour les d√©tections (par d√©faut : 0.5).
IOU_THRESHOLD : Seuil de l'Intersection over Union pour le NMS (par d√©faut : 0.45).
Vous pouvez ajuster ces param√®tres directement dans le script.

## Fonctionnement:
Le script capture une capture d'√©cran de votre √©cran, la redimensionne, effectue une d√©tection d'objets avec votre mod√®le YOLOv8, puis affiche le r√©sultat avec les bo√Ætes englobantes et les √©tiquettes.
Appuyez sur la touche 'q' pour quitter la boucle et fermer la fen√™tre.

## Notes: 
Assurez-vous que votre mod√®le YOLOv8 est compatible avec la version de ultralytics que vous utilisez.
Si vous rencontrez des erreurs, v√©rifiez le chemin du fichier de mod√®le et assurez-vous que les librairies sont correctement install√©es.
Ce script utilise l'√©cran principal. Si vous souhaitez capturer un autre √©cran, vous devrez ajuster les param√®tres de pyautogui.screenshot().
Les performances peuvent varier en fonction de la puissance de votre ordinateur et de la taille de l'√©cran.

## Am√©liorations possibles
Ajouter des options pour personnaliser la taille de la fen√™tre d'affichage.
Permettre de s√©lectionner un autre √©cran √† capturer.
Ajouter un compteur de FPS (images par seconde) pour √©valuer les performances.
Utiliser un thread ou un processus s√©par√© pour la capture d'√©cran afin d'am√©liorer les performances.



## 5 Run with an Arduino to tracking a target
##Mat√©riel
Un Arduino connect√© √† votre ordinateur via le port s√©rie.
Un jeu FPS.

##Utilisation
#Placez votre mod√®le : Copiez votre fichier de mod√®le YOLOv8 entra√Æn√© (best_fort.pt) dans le m√™me r√©pertoire que ce script.
Connectez l'Arduino : Connectez votre Arduino √† votre ordinateur et notez le port COM utilis√© (par exemple, COM10).

##Modifiez le script :
Remplacez 'COM10' dans la variable ser par le port COM correct de votre Arduino.
Ajustez les param√®tres suivants dans le script en fonction de votre configuration :
CONFIDENCE_THRESHOLD : Seuil de confiance pour la d√©tection.
IOU_THRESHOLD : Seuil IOU pour le NMS.
frame_width, frame_height : Taille de la fen√™tre de capture et de traitement.
GAME_WIDTH, GAME_HEIGHT : R√©solution du jeu.
DEAD_ZONE : Zone morte autour du centre de l'√©cran o√π les mouvements ne sont pas envoy√©s √† l'Arduino.
EXCLUDED_REGION : Zone de l'√©cran √† exclure de la d√©tection (utile pour √©viter de cibler des √©l√©ments de l'interface du jeu).


##Ex√©cutez le script :
Bash

python Aimbot_Assist_w_Arduino.py
Fonctionnement

Le script capture une portion de l'√©cran, effectue une d√©tection d'objets avec YOLOv8, s√©lectionne la cible la plus proche du centre de l'√©cran et envoie les coordonn√©es de la cible √† l'Arduino. L'Arduino peut ensuite √™tre programm√© pour contr√¥ler la souris ou d'autres p√©riph√©riques d'entr√©e pour viser dans le jeu.

Ctrl : Active/d√©sactive la d√©tection.
Le script affiche une fen√™tre avec le flux vid√©o, les d√©tections, la cible s√©lectionn√©e (un cercle vert) et la zone d'exclusion (un rectangle rouge).

##Configuration du jeu
Assurez-vous que les param√®tres du jeu (r√©solution, sensibilit√© de la souris) sont configur√©s de mani√®re appropri√©e pour fonctionner avec le script.  Il peut √™tre n√©cessaire d'ajuster les param√®tres du script (en particulier SCALE_FACTOR, OFFSET_X, OFFSET_Y) pour une performance optimale.

##Code Arduino (exemple) 
Voici un exemple de code Arduino qui re√ßoit les commandes du script Python et simule des mouvements de souris :

```
C++
#include <Mouse.h>

void setup() {
  Serial.begin(9500);
  Mouse.begin();
}

void loop() {
  if (Serial.available() > 0) {
    String command = Serial.readStringUntil('\n');
    int x = command.substring(0, command.indexOf(',')).toInt();
    int y = command.substring(command.indexOf(',') + 1).toInt();

    Mouse.move(x, y, 0); // D√©placer la souris (x, y, 0)
  }
}

```
##Important : Ce code Arduino est un exemple. Vous devrez peut-√™tre l'adapter en fonction de vos besoins et de la fa√ßon dont vous souhaitez contr√¥ler le jeu.

##Limitations
Les performances peuvent varier en fonction de la puissance de l'ordinateur, de la complexit√© du mod√®le YOLOv8 et de la r√©solution de l'√©cran.
Le suivi de cible peut √™tre perdu si l'objet cible est obstru√© ou sort de l'√©cran.
Ce script est un point de d√©part. Vous devrez probablement l'affiner pour obtenir les r√©sultats souhait√©s dans votre jeu sp√©cifique.


## Conclusion
Avec ces √©tapes, vous pouvez entra√Æner un mod√®le YOLOv8 sur un dataset personnalis√© et le convertir au format ONNX pour une int√©gration facile dans vos projets.

### Voici un petit exemple pour un FPS 
https://streamable.com/xf2lst 

[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/lFrydrUvbJc/0.jpg)](https://www.youtube.com/watch?v=lFrydrUvbJc)

https://youtu.be/lFrydrUvbJc?si=hPbMRpqrRUQb6bWZ

Le script fournit g√®re √©galement les zones d'exclusions, afin que la detection ne se fasse pas dans cette frame.
Si vous voulez trouver et entrainer d'autres mod√®les, https://universe.roboflow.com 


